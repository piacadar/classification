{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1151, 20)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quality</th>\n",
       "      <th>prescreen</th>\n",
       "      <th>ma2</th>\n",
       "      <th>ma3</th>\n",
       "      <th>ma4</th>\n",
       "      <th>ma5</th>\n",
       "      <th>ma6</th>\n",
       "      <th>ma7</th>\n",
       "      <th>exudate8</th>\n",
       "      <th>exudate9</th>\n",
       "      <th>exudate10</th>\n",
       "      <th>exudate11</th>\n",
       "      <th>exudate12</th>\n",
       "      <th>exudate13</th>\n",
       "      <th>exudate14</th>\n",
       "      <th>exudate15</th>\n",
       "      <th>euDist</th>\n",
       "      <th>diameter</th>\n",
       "      <th>amfm_class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>49.895756</td>\n",
       "      <td>17.775994</td>\n",
       "      <td>5.270920</td>\n",
       "      <td>0.771761</td>\n",
       "      <td>0.018632</td>\n",
       "      <td>0.006864</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.486903</td>\n",
       "      <td>0.100025</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>57.709936</td>\n",
       "      <td>23.799994</td>\n",
       "      <td>3.325423</td>\n",
       "      <td>0.234185</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>0.520908</td>\n",
       "      <td>0.144414</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>54</td>\n",
       "      <td>47</td>\n",
       "      <td>33</td>\n",
       "      <td>55.831441</td>\n",
       "      <td>27.993933</td>\n",
       "      <td>12.687485</td>\n",
       "      <td>4.852282</td>\n",
       "      <td>1.393889</td>\n",
       "      <td>0.373252</td>\n",
       "      <td>0.041817</td>\n",
       "      <td>0.007744</td>\n",
       "      <td>0.530904</td>\n",
       "      <td>0.128548</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>53</td>\n",
       "      <td>53</td>\n",
       "      <td>50</td>\n",
       "      <td>43</td>\n",
       "      <td>31</td>\n",
       "      <td>40.467228</td>\n",
       "      <td>18.445954</td>\n",
       "      <td>9.118901</td>\n",
       "      <td>3.079428</td>\n",
       "      <td>0.840261</td>\n",
       "      <td>0.272434</td>\n",
       "      <td>0.007653</td>\n",
       "      <td>0.001531</td>\n",
       "      <td>0.483284</td>\n",
       "      <td>0.114790</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>39</td>\n",
       "      <td>27</td>\n",
       "      <td>18.026254</td>\n",
       "      <td>8.570709</td>\n",
       "      <td>0.410381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.475935</td>\n",
       "      <td>0.123572</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>43</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>37</td>\n",
       "      <td>29</td>\n",
       "      <td>28.356400</td>\n",
       "      <td>6.935636</td>\n",
       "      <td>2.305771</td>\n",
       "      <td>0.323724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.502831</td>\n",
       "      <td>0.126741</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>27</td>\n",
       "      <td>25</td>\n",
       "      <td>16</td>\n",
       "      <td>15.448398</td>\n",
       "      <td>9.113819</td>\n",
       "      <td>1.633493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.541743</td>\n",
       "      <td>0.139575</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20.679649</td>\n",
       "      <td>9.497786</td>\n",
       "      <td>1.223660</td>\n",
       "      <td>0.150382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.576318</td>\n",
       "      <td>0.071071</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>21</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>66.691933</td>\n",
       "      <td>23.545543</td>\n",
       "      <td>6.151117</td>\n",
       "      <td>0.496372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500073</td>\n",
       "      <td>0.116793</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>75</td>\n",
       "      <td>73</td>\n",
       "      <td>71</td>\n",
       "      <td>64</td>\n",
       "      <td>47</td>\n",
       "      <td>22.141784</td>\n",
       "      <td>10.054384</td>\n",
       "      <td>0.874633</td>\n",
       "      <td>0.099780</td>\n",
       "      <td>0.023386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.560959</td>\n",
       "      <td>0.109134</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   quality  prescreen  ma2  ma3  ma4  ma5  ma6  ma7   exudate8   exudate9  \\\n",
       "0        1          1   22   22   22   19   18   14  49.895756  17.775994   \n",
       "1        1          1   24   24   22   18   16   13  57.709936  23.799994   \n",
       "2        1          1   62   60   59   54   47   33  55.831441  27.993933   \n",
       "3        1          1   55   53   53   50   43   31  40.467228  18.445954   \n",
       "4        1          1   44   44   44   41   39   27  18.026254   8.570709   \n",
       "5        1          1   44   43   41   41   37   29  28.356400   6.935636   \n",
       "6        1          0   29   29   29   27   25   16  15.448398   9.113819   \n",
       "7        1          1    6    6    6    6    2    1  20.679649   9.497786   \n",
       "8        1          1   22   21   18   15   13   10  66.691933  23.545543   \n",
       "9        1          1   79   75   73   71   64   47  22.141784  10.054384   \n",
       "\n",
       "   exudate10  exudate11  exudate12  exudate13  exudate14  exudate15    euDist  \\\n",
       "0   5.270920   0.771761   0.018632   0.006864   0.003923   0.003923  0.486903   \n",
       "1   3.325423   0.234185   0.003903   0.003903   0.003903   0.003903  0.520908   \n",
       "2  12.687485   4.852282   1.393889   0.373252   0.041817   0.007744  0.530904   \n",
       "3   9.118901   3.079428   0.840261   0.272434   0.007653   0.001531  0.483284   \n",
       "4   0.410381   0.000000   0.000000   0.000000   0.000000   0.000000  0.475935   \n",
       "5   2.305771   0.323724   0.000000   0.000000   0.000000   0.000000  0.502831   \n",
       "6   1.633493   0.000000   0.000000   0.000000   0.000000   0.000000  0.541743   \n",
       "7   1.223660   0.150382   0.000000   0.000000   0.000000   0.000000  0.576318   \n",
       "8   6.151117   0.496372   0.000000   0.000000   0.000000   0.000000  0.500073   \n",
       "9   0.874633   0.099780   0.023386   0.000000   0.000000   0.000000  0.560959   \n",
       "\n",
       "   diameter  amfm_class  label  \n",
       "0  0.100025           1      0  \n",
       "1  0.144414           0      0  \n",
       "2  0.128548           0      1  \n",
       "3  0.114790           0      0  \n",
       "4  0.123572           0      1  \n",
       "5  0.126741           0      1  \n",
       "6  0.139575           0      1  \n",
       "7  0.071071           1      0  \n",
       "8  0.116793           0      1  \n",
       "9  0.109134           0      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data from csv file\n",
    "col_names = []\n",
    "for i in range(20):\n",
    "    if i == 0:\n",
    "        col_names.append('quality')\n",
    "    if i == 1:\n",
    "        col_names.append('prescreen')\n",
    "    if i >= 2 and i <= 7:\n",
    "        col_names.append('ma' + str(i))\n",
    "    if i >= 8 and i <= 15:\n",
    "        col_names.append('exudate' + str(i))\n",
    "    if i == 16:\n",
    "        col_names.append('euDist')\n",
    "    if i == 17:\n",
    "        col_names.append('diameter')\n",
    "    if i == 18:\n",
    "        col_names.append('amfm_class')\n",
    "    if i == 19:\n",
    "        col_names.append('label')\n",
    "\n",
    "data = pd.read_csv(\"messidor_features.txt\", names = col_names)\n",
    "print(data.shape)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1151, 19) (1151,)\n",
      "\n",
      "   quality  prescreen  ma2  ma3  ma4  ma5  ma6  ma7   exudate8   exudate9  \\\n",
      "0        1          1   22   22   22   19   18   14  49.895756  17.775994   \n",
      "1        1          1   24   24   22   18   16   13  57.709936  23.799994   \n",
      "2        1          1   62   60   59   54   47   33  55.831441  27.993933   \n",
      "3        1          1   55   53   53   50   43   31  40.467228  18.445954   \n",
      "4        1          1   44   44   44   41   39   27  18.026254   8.570709   \n",
      "\n",
      "   exudate10  exudate11  exudate12  exudate13  exudate14  exudate15    euDist  \\\n",
      "0   5.270920   0.771761   0.018632   0.006864   0.003923   0.003923  0.486903   \n",
      "1   3.325423   0.234185   0.003903   0.003903   0.003903   0.003903  0.520908   \n",
      "2  12.687485   4.852282   1.393889   0.373252   0.041817   0.007744  0.530904   \n",
      "3   9.118901   3.079428   0.840261   0.272434   0.007653   0.001531  0.483284   \n",
      "4   0.410381   0.000000   0.000000   0.000000   0.000000   0.000000  0.475935   \n",
      "\n",
      "   diameter  amfm_class  \n",
      "0  0.100025           1  \n",
      "1  0.144414           0  \n",
      "2  0.128548           0  \n",
      "3  0.114790           0  \n",
      "4  0.123572           0  \n"
     ]
    }
   ],
   "source": [
    "# Separate the feature columns from the class label column\n",
    "\n",
    "X = data.drop(['label'], axis = 1)\n",
    "y = data['label']\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "print()\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Support Vector Machines (SVM) and Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2. For some classification algorithms, like KNN, SVMs, and Neural Nets, scaling of the data is critical for the algorithm to operate correctly. For other classification algorithms, like Naive Bayes, and Decision Trees, data scaling is not necessary (take a minute to think about why that is the case). \n",
    "\n",
    "We discussed in class how the data scaling should happen on the _training set only_, which means that it should happen _inside_ of the cross validation loop. In other words, in each fold of the cross validation, the data will be separated in to training and test sets. The scaling (calculating mean and std, for instance) should happen based on the values in the _traning set only_. Then the test set can be scaled using the values found on the training set. (Refer to the concept of [data leakage](https://machinelearningmastery.com/data-leakage-machine-learning/).)\n",
    "\n",
    "In order to do this with scikit-learn, you must create what's called a `Pipeline` and pass that in to the cross validation. This is a very important concept for Data Mining and Machine Learning, so let's practice it here.\n",
    "\n",
    "Do the following:\n",
    "* Create a `sklearn.preprocessing.StandardScaler` object to standardize the dataset’s features (mean = 0 and variance = 1). Do not call `fit` on it yet. Just create the `StandardScaler` object.\n",
    "* Create a sklearn.svm.SVC classifier (do not set any arguments - use the defaults). Do not call fit on it yet. Just create the SVC object.\n",
    "* Create a `sklearn.pipeline.Pipeline` and set the `steps` to the scaler and the SVC objects that you just created. \n",
    "* Pass the `pipeline` in to a `cross_val_score` as the estimator, along with the features and the labels, and use a 5-fold-CV. \n",
    "\n",
    "In each fold of the cross validation, the training phase will use _only_ the training data for scaling and training the model. Then the testing phase will scale the test data into the scaled space (found on the training data) and run the test data through the trained classifier, to return an accuracy measurement for each fold. Print the average accuracy across all 5 folds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.11368341803124\n"
     ]
    }
   ],
   "source": [
    "# Create StandardScaler and SVC Object\n",
    "scaler = StandardScaler()\n",
    "svc = SVC()\n",
    "\n",
    "# Create pipeline and set steps to scaler and SVC objects\n",
    "pipe = Pipeline(steps = [('Scaler', scaler), ('svc', svc)])\n",
    "\n",
    "scores = cross_val_score(pipe, X, y, cv = 5)\n",
    "#Print accuracy\n",
    "print('Accuracy:', scores.mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best kernel: {'svc__kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "# For the 'svm' part of the pipeline, tune the 'kernel' hyperparameter\n",
    "param_grid = {'svc__kernel': ['linear', 'rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "# Create GridSearchCV that takes in pipeline\n",
    "grid = GridSearchCV(pipe, param_grid, cv = 5)\n",
    "grid.fit(X, y)\n",
    "# Print best kernel\n",
    "print(\"Best kernel:\", grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4. Now put what you did in Q3 in to an outer CV loop to evaluate the accuracy of using that best-found kernel on unseen test data. \n",
    "* Pass the `GridSearchCV` in to a `cross_val_score` with 5-fold-CV. Print out the accuracy.\n",
    "\n",
    "Note that the accuracy increases from Q2 because of a better choice of kernel function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.28646715603239\n"
     ]
    }
   ],
   "source": [
    "# Pass the GridSearchCV in to a cross_val_score with 5-fold-CV\n",
    "grid_score = cross_val_score(grid, X, y, cv = 5, scoring = 'accuracy')\n",
    "# Print accuracy\n",
    "print('Accuracy:', grid_score.mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5. Let's see if we can get the accuracy even higher by tuning additional hyperparameters. SVMs have a parameter called 'C' that is the cost for a misclassification. (More info [here](https://medium.com/@pushkarmandot/what-is-the-significance-of-c-value-in-support-vector-machine-28224e852c5a)).\n",
    "* Create a parameter grid that includes the kernel (as you have above) and the C value as well. Try values of C from 50 to 100 by increments of 10. (You can use the range function to help you with this.)\n",
    "* Create a `GridSearchCV` with the pipeline from above, this new parameter grid, and a 5-fold-CV.\n",
    "* Pass the `GridSearchCV` into a `cross_val_score` with a 5-fold-CV and print out the accuracy.\n",
    "\n",
    "Be patient as this can take some time to run. Note that the accurcay has increased even further because the best value of C was found and used on the test data.\n",
    "\n",
    "Now we're actually starting to get closer to some decent accuracies on this dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.54357236965933\n"
     ]
    }
   ],
   "source": [
    "# Create parameter grid and GridSearchCV with pipeline from above\n",
    "params = {'svc__C': range(50, 110, 10), 'svc__kernel': ['linear']}\n",
    "grid_search = GridSearchCV(pipe, params, cv = 5)\n",
    "\n",
    "# Pass the GridSearchCV into a cross_val_score with a 5-fold-CV \n",
    "grid_search_score = cross_val_score(grid_search, X, y, cv = 5)\n",
    "# Print accuracy\n",
    "print('Accuracy:', grid_search_score.mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Neural Networks (NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'mlp__activation': 'relu', 'mlp__hidden_layer_sizes': (40,)}\n",
      "Accuracy: 72.28609072087335\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline that includes scaling and an MLPClassifier\n",
    "mlp = MLPClassifier()\n",
    "parameters = {'mlp__activation': ['logistic', 'tanh', 'relu'], 'mlp__hidden_layer_sizes': [(10,), (20,), (30,), (40,), (50,), (60,)]}\n",
    "pipe_nn = Pipeline(steps = [('Scaler', scaler), ('mlp', mlp)])\n",
    "grid_nn = GridSearchCV(pipe_nn, parameters, cv = 5)\n",
    "\n",
    "# Fit GridSearchCV to determine best parameters\n",
    "grid_nn.fit(X, y)\n",
    "print(\"Best Params:\", grid_nn.best_params_)\n",
    "\n",
    "scores_nn = cross_val_score(grid_nn, X, y, cv = 5)\n",
    "print('Accuracy:', scores_nn.mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Ensemble Classifiers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A. Random Forests**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'max_depth': 43, 'max_features': 'sqrt', 'min_samples_leaf': 12}\n",
      "Accuracy: 68.28496141539621\n"
     ]
    }
   ],
   "source": [
    "# Use Random Forests to classify data\n",
    "rfc = RandomForestClassifier()\n",
    "params_rfc = {'max_depth': range(35, 56, 1), 'min_samples_leaf': [8, 10, 12], 'max_features': ['sqrt', 'log2']}\n",
    "\n",
    "grid_rfc = GridSearchCV(rfc, params_rfc, cv = 5)\n",
    "grid_rfc.fit(X, y)\n",
    "print('Best Params:', grid_rfc.best_params_)\n",
    "\n",
    "# GridSearchCV in a cross_val_score with 5-fold CV\n",
    "scores_rfc = cross_val_score(grid_rfc, X, y, cv = 5, scoring = 'accuracy')\n",
    "print('Accuracy:', scores_rfc.mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B. AdaBoost**\n",
    "\n",
    "Random Forests are a kind of ensemble classifier where many estimators are built independently in parallel. In contrast, there is another method of creating an ensemble classifier called *boosting*. Here the classifiers are trained one-by-one in sequence and each time the sampling of the training set depends on the performance of previously generated models.\n",
    "\n",
    "Q8. Evaluate a `sklearn.ensemble.AdaBoostClassifier` classifier on the data. By default, `AdaBoostClassifier` uses decision trees as the base classifiers (but this can be changed). \n",
    "* Use a GridSearchCV to find the best number of trees in the ensemble (`n_estimators`). Try values from 50-250 with increments of 25. (you can use the range function to help you with this.)\n",
    "* Wrap your GridSearchCV in a cross_val_score with 5-fold CV to report the accuracy of the model.\n",
    "\n",
    "Be patient, this can take a few minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 250}\n",
      "Accuracy: 71.32806324110673\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "params_ada = {'n_estimators': range(50, 275, 25)}\n",
    "grid_ada = GridSearchCV(ada, params_ada, cv = 5)\n",
    "\n",
    "# Find best number of trees in ensemble\n",
    "grid_ada.fit(X, y)\n",
    "print('Best params:', grid_ada.best_params_)\n",
    "\n",
    "# Wrap GridSearchCV in a cross_val_score with 5-fold CV\n",
    "scores_ada = cross_val_score(grid_ada, X, y, cv = 5)\n",
    "print('Accuracy:', scores_ada.mean() * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Deploying a final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'mlp__activation': 'relu', 'mlp__hidden_layer_sizes': (60,)}\n",
      "Accuracy: 73.93570807993049\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "params_final = {'mlp__activation': ['logistic', 'tanh', 'relu'], 'mlp__hidden_layer_sizes': [(10,), (20,), (30,), (40,), (50,), (60,)]}\n",
    "pipe_final = Pipeline(steps = [('Scaler', scaler), ('mlp', mlp)])\n",
    "grid_final = GridSearchCV(pipe_final, parameters, cv = 5)\n",
    "\n",
    "# Fit GridSearchCV to determine best parameters\n",
    "grid_final.fit(X, y)\n",
    "print(\"Best Params:\", grid_final.best_params_)\n",
    "print('Accuracy:', grid_final.best_score_ * 100)\n",
    "\n",
    "# Set this final_model to final model\n",
    "final_model = grid_final\n",
    "\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(final_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive for disease\n"
     ]
    }
   ],
   "source": [
    "# Use to record to classify\n",
    "record = [ 0.05905386, 0.2982129, 0.68613149, 0.75078865, 0.87119216, 0.88615694,\n",
    "  0.93600623, 0.98369184, -0.47426472, -0.57642756, -0.53115361, -0.42789774,\n",
    " -0.21907738, -0.20090532, -0.21496782, -0.2080998, 0.06692373, -2.81681183,\n",
    " -0.7117194 ]\n",
    " \n",
    "# Load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# Classify record\n",
    "ans = loaded_model.predict([record])\n",
    "\n",
    "if ans == 1:\n",
    "    print('Positive for disease')\n",
    "else:\n",
    "    print('Negative for disease')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
